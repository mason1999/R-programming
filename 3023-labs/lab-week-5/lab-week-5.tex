\documentclass[12pt, a4paper]{article}\usepackage[]{graphicx}\usepackage[]{color}
% maxwidth is the original width if it is less than linewidth
% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
\input{./everything/everything.tex}

% for the mathscr
\usepackage{mathrsfs}
% easier for bold symbols
\newcommand{\bs}[1]{\boldsymbol{#1}}
% partial derivatives
\newcommand{\partiald}[1]{\frac{\delta}{\delta#1}}
% for estimators
\newcommand{\wh}[1]{\widehat{#1}}
% for examples
\newcommand{\gb}[1]{\greybox{#1}}


\titleformat{\section}{\normalfont\Large\bfseries}{}{0pt}{}
% for sets and curly letters
\newcommand{\cur}[1]{\mathcal{#1}}
\newcommand{\scr}[1]{\mathscr{#1}}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}
% refer to https://yihui.org/knitr/options/#code-decoration for more options


% (1) Remember that we want the default page style
% (2) but for this page we want an empty page style for the title 
% (3) we input our title 
% (4) we call a new page and reset the page counter to 1
\pagestyle{default}
\thispagestyle{empty}
\input{./title_page.tex}
\newpage
\setcounter{page}{1}
We shall compare three different estimators of a binomial success probability. If $Y \thicksim B(2, \theta)$ then we have: $P(Y = 0) = (1 - \theta^2)$, $P(Y = 1) = 2\theta(1 - \theta)$, $P(Y = 2) = \theta^2$. Moreover, if we have an iid sample $Y_1, Y_2,..., Y_n$ then if we define:

\begin{itemize}
  \item $N_0 = \sum_{i = 1}^n1_{\{Y_i = 0\}}$ as the number of 0's $\implies N_0 \thicksim B(n, (1 - \theta)^2)$
  \item $N_1 = \sum_{i = 1}^n1_{\{Y_i = 1\}}$ as the number of 1's  $\implies N_1\thicksim B(n, 2\theta(1 - \theta))$
  \item $N_2 = \sum_{i = 1}^n1_{\{Y_i = 2\}}$ as the number of 2's $\implies N_2 \thicksim B(n, \theta^2)$
\end{itemize}

The usual estimator of $\theta$ based on an iid sample $Y_1, Y_2, ... , Y_n$ is a function of $\overbar{1}{Y}= \frac{1}{n}\sum_{i = 1}^nY_i$

\begin{enumerate}[label={\bfseries\arabic*.}]
\item Determine an unbiased estimator of $\theta$ which is a \textit{linear} function of $\overbar{1}{Y}$. Call it $\hat{\theta_1}$

{\setlength{\leftskip}{3ex}
\tbf{Solution}

To find an unbiased estimator of $\theta$ we first note that:
\begin{align*}
\E[\overbar{0.5}{Y}] & = \frac{1}{n}\sum_{i = 1}^n\E[Y_1]\\
& = \E[Y_1] \\
& = 2\theta
\end{align*}
Hence we should define an unbiased estimator $\hat{\theta_1}$ by: 
$$\hat{\theta_1} = \frac{1}{2}\overbar{0.2}{Y}$$
}
\item Determine an unbiased estimator of $\theta$ which is a \textit{nonlinear} function of $N_0$ (hint: use method of moments, i.e. set equal to expectation and solve for $\theta$). Call it $\hat{\theta_0}$

{\setlength{\leftskip}{3ex}
\tbf{Solution}

To find an unbiased estimator of $\theta$ we recall the method of moments. We have that $1_{\{Y_i = 0\}} \thicksim bernoulli((1 - \theta)^2)$. Hence we have that $\E\brac{1_{\{Y_i = 0\}}} = (1 - \theta)^2$. With the random sample $1_{\{Y_1 = 0\}}, 1_{\{Y_2 = 0\}}, ..., 1_{\{Y_n = 0\}}$. We have that (by the method of moments) $ (1 - \theta)^2 = \frac{1}{n}\sum_{i = 1}^n 1_{\{Y_i = 0\}} \implies (1 - \theta)^2 = \frac{1}{n}N_0 \implies \hat{\theta_0} = 1 - \sqrt{\frac{N_0}{n}}$

}

\item Determine an unbiased estimator of $\theta$ which is a \textit{nonlinear} function of $N_2$ (hint: use method of moments, i.e. set equal to expectation and solve for $\theta$). Call it $\hat{\theta_2}$

{\setlength{\leftskip}{3ex}
\tbf{Solution}

To find an unbiased estimator of $\theta$ we recall the method of moments. We have that $1_{\{Y_i = 2\}} \thicksim bernoulli(\theta^2)$. Hence we have that $\E\brac{1_{\{Y_i = 2\}}} =\theta^2$. With the random sample $1_{\{Y_1 = 2\}}, 1_{\{Y_2 = 2\}},$ 

$..., 1_{\{Y_n = 2\}}$. We have that (by the method of moments) $ \theta^2 = \frac{1}{n}\sum_{i = 1}^n 1_{\{Y_i = 2\}} \implies \theta^2 = \frac{1}{n}N_2 \implies \hat{\theta_2} = \sqrt{\frac{N_2}{n}}$

}

\item We shall simulate a sample if $n = 100$ iid such $Y_i$â€™s and compute the values of these three estimators and then compare their mean squared errors, for a fine grid of $\theta$ values.

{\setlength{\leftskip}{3ex}
\tbf{Solution}

We want to now compare the variance of $\hat{\theta_0}, \hat{\theta_1}$ and $\hat{\theta_2}$ with the CRLB of $\frac{\theta\rbrac{1 - \theta}}{2n}$. 

\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{# sample size}
\hlstd{n} \hlkwb{=} \hlnum{100}
\hlcom{# Number of simulation iterations}
\hlstd{N} \hlkwb{=} \hlnum{1000}
\hlcom{# theta values and length of this vector of values}
\hlstd{thetaVals} \hlkwb{=} \hlstd{(}\hlnum{1}\hlopt{:}\hlnum{39}\hlstd{)}\hlopt{/}\hlnum{40}
\hlstd{len} \hlkwb{=} \hlkwd{length}\hlstd{(thetaVals)}
\hlcom{# Declare the mean squared error vectors to be plotted against the theta values}
\hlstd{mse0} \hlkwb{=} \hlkwd{vector}\hlstd{(}\hlkwc{mode} \hlstd{=} \hlstr{"numeric"}\hlstd{,} \hlkwc{length} \hlstd{= len)}
\hlstd{mse1} \hlkwb{=} \hlkwd{vector}\hlstd{(}\hlkwc{mode} \hlstd{=} \hlstr{"numeric"}\hlstd{,} \hlkwc{length} \hlstd{= len)}
\hlstd{mse2} \hlkwb{=} \hlkwd{vector}\hlstd{(}\hlkwc{mode} \hlstd{=} \hlstr{"numeric"}\hlstd{,} \hlkwc{length} \hlstd{= len)}

\hlcom{# Declare temporary variables to be used in the loop}
\hlstd{temp0} \hlkwb{=} \hlkwd{vector}\hlstd{(}\hlkwc{mode} \hlstd{=} \hlstr{"numeric"}\hlstd{,} \hlkwc{length} \hlstd{= N)}
\hlstd{temp1} \hlkwb{=} \hlkwd{vector}\hlstd{(}\hlkwc{mode} \hlstd{=} \hlstr{"numeric"}\hlstd{,} \hlkwc{length} \hlstd{= N)}
\hlstd{temp2} \hlkwb{=} \hlkwd{vector}\hlstd{(}\hlkwc{mode} \hlstd{=} \hlstr{"numeric"}\hlstd{,} \hlkwc{length} \hlstd{= N)}

\hlkwa{for} \hlstd{(i} \hlkwa{in} \hlnum{1}\hlopt{:}\hlstd{len) \{}
  \hlcom{# We set the current value of theta. }
  \hlstd{currThetaValue} \hlkwb{=} \hlstd{thetaVals[i]}

  \hlcom{# For the current theta value, we calculate the mean squared error for all }
  \hlcom{# three estimators}
  \hlkwa{for} \hlstd{(j} \hlkwa{in} \hlnum{1}\hlopt{:}\hlstd{N) \{}

    \hlcom{# step 1: Draw a sample of n binomal observations}
    \hlstd{obs} \hlkwb{=} \hlkwd{rbinom}\hlstd{(}\hlkwc{n} \hlstd{= n,} \hlkwc{size} \hlstd{=} \hlnum{2}\hlstd{,} \hlkwc{prob} \hlstd{= currThetaValue)}

    \hlcom{# calculate the value of theta0, theta1 and theta2}
    \hlstd{temp0[j]} \hlkwb{=} \hlnum{1} \hlopt{-} \hlkwd{sqrt}\hlstd{(}\hlkwd{sum}\hlstd{(obs} \hlopt{==} \hlnum{0}\hlstd{)}\hlopt{/}\hlstd{n)}
    \hlstd{temp1[j]} \hlkwb{=} \hlnum{1}\hlopt{/}\hlnum{2} \hlopt{*} \hlkwd{mean}\hlstd{(obs)}
    \hlstd{temp2[j]} \hlkwb{=} \hlkwd{sqrt}\hlstd{(}\hlkwd{sum}\hlstd{(obs} \hlopt{==} \hlnum{2}\hlstd{)}\hlopt{/}\hlstd{n)}

  \hlstd{\}}

  \hlstd{temp0} \hlkwb{=} \hlstd{(temp0} \hlopt{-} \hlstd{currThetaValue)}\hlopt{^}\hlnum{2}
  \hlstd{temp1} \hlkwb{=} \hlstd{(temp1} \hlopt{-} \hlstd{currThetaValue)}\hlopt{^}\hlnum{2}
  \hlstd{temp2} \hlkwb{=} \hlstd{(temp2} \hlopt{-} \hlstd{currThetaValue)}\hlopt{^}\hlnum{2}

  \hlstd{mse0[i]} \hlkwb{=} \hlkwd{mean}\hlstd{(temp0)}
  \hlstd{mse1[i]} \hlkwb{=} \hlkwd{mean}\hlstd{(temp1)}
  \hlstd{mse2[i]} \hlkwb{=} \hlkwd{mean}\hlstd{(temp2)}
\hlstd{\}}
\end{alltt}
\end{kframe}
\end{knitrout}
After all this processing, we can now plot the values of the mean squared error for each value of $\theta_k$ (where $k \in \cbrac{1, 2, 3, ..., 39}$). We also plot the 
Cramer Rao Lower Bound and show the result below:

\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{# returns the min and max value for the range}
\hlstd{yRange} \hlkwb{=} \hlkwd{range}\hlstd{(}\hlkwd{c}\hlstd{(mse0, mse1, mse2))}
\hlcom{# plot the best estimator theta1 hat}
\hlkwd{plot}\hlstd{(}\hlkwc{x} \hlstd{= thetaVals,} \hlkwc{y} \hlstd{= mse1,} \hlkwc{col} \hlstd{=} \hlstr{"red"}\hlstd{,} \hlkwc{ylim} \hlstd{= yRange,}
     \hlkwc{type} \hlstd{=} \hlstr{"l"}\hlstd{,} \hlkwc{main} \hlstd{=} \hlstr{"Empirical MSE's"}\hlstd{,}
     \hlkwc{xlab} \hlstd{=} \hlstr{"Theta values"}\hlstd{,}
     \hlkwc{ylab} \hlstd{=} \hlstr{"mean squared error"}\hlstd{)}
\hlcom{# plot theta0 hat}
\hlkwd{lines}\hlstd{(}\hlkwc{x} \hlstd{= thetaVals,} \hlkwc{y} \hlstd{= mse0,} \hlkwc{col} \hlstd{=} \hlstr{"blue"}\hlstd{)}
\hlcom{# plot theta2 hat}
\hlkwd{lines}\hlstd{(}\hlkwc{x} \hlstd{= thetaVals,} \hlkwc{y} \hlstd{= mse2,} \hlkwc{col} \hlstd{=} \hlstr{"DarkGreen"}\hlstd{)}
\hlcom{# plot the CRLB}
\hlkwd{curve}\hlstd{(}\hlnum{0.5} \hlopt{*} \hlstd{x} \hlopt{*} \hlstd{(}\hlnum{1} \hlopt{-} \hlstd{x)}\hlopt{/}\hlstd{n,} \hlkwc{add} \hlstd{=} \hlnum{TRUE}\hlstd{,} \hlkwc{lty} \hlstd{=} \hlnum{2}\hlstd{)}
\hlcom{# legend}
\hlkwd{legend}\hlstd{(}\hlkwc{x} \hlstd{=} \hlstr{"top"}\hlstd{,}
       \hlkwc{legend} \hlstd{=} \hlkwd{c}\hlstd{(}\hlstr{"using average"}\hlstd{,} \hlstr{"using N0"}\hlstd{,} \hlstr{"using N2"}\hlstd{,} \hlstr{"CRLB"}\hlstd{),}
       \hlkwc{col} \hlstd{=} \hlkwd{c}\hlstd{(}\hlstr{"red"}\hlstd{,} \hlstr{"blue"}\hlstd{,} \hlstr{"DarkGreen"}\hlstd{,} \hlstr{"black"}\hlstd{),}
       \hlkwc{lty} \hlstd{=} \hlkwd{c}\hlstd{(}\hlnum{1}\hlstd{,} \hlnum{1}\hlstd{,} \hlnum{1}\hlstd{,} \hlnum{2}\hlstd{))}
\end{alltt}
\end{kframe}

{\centering \includegraphics[width=\maxwidth]{figure/unnamed-chunk-3-1} 

}


\end{knitrout}

}
\end{enumerate}

\end{document}
