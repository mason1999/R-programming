---
title: "lab 2"
author: "Mason Wong"
date: "15th March 2022"
output: pdf_document
---
```{r setup, warning=F, message=F}
library(tidyverse)
library(dplyr)
# library(broom)
# library(patchwork)
knitr::opts_chunk$set(echo = TRUE, tidy = FALSE, fig.align = "center", fig.pos = "H")
```

# Question 1

```{r}
olympic = read.table("~/Desktop/R-programming/3002-labs/lab-2/olympic.txt", sep = "\t", header = TRUE)
head(olympic, 6)
summary(olympic)
tail(olympic, 6)
```
The possible unusual features about the `olympic` dataset are: 
- The distances are in inches. We should aim to convert them into meters
- The years are relative to 1900's
- There are 3 NA observations for the last 3 observations. 

We change the inches to meters
```{r}
convert_inch_to_m = function(x) {
  return(x/39.3701)
}
olympicMetric = olympic %>% 
  mutate(across(c(HighJump, DiscusThrow, LongJump), convert_inch_to_m)) %>% 
  mutate(Year = Year + 1900)
```

# Question 2
(a) 

```{r}
olympicMetric %>% 
  ggplot(aes(x = LongJump, y = HighJump)) + 
  geom_point() + 
  labs(x = "Long jump", y = "High jump")
```
We see that there appears to be a linear trend. 

(b) we fit a simple linear regression model. 

```{r}
olympicLm = lm(HighJump ~ LongJump, data = olympicMetric)
```

(c) we find a least squares estimate for the parameters $(\beta_1, \beta_2, \sigma^2)$ using a `summary` output from `olympicLm`

```{r}
data_summary = summary(olympicLm)
data_summary
```
From the `R` output we see that 

- $\hat{\beta_0}$ = `r data_summary$coefficients[1]`

- $\hat{\beta_1}$ = `r data_summary$coefficients[2]`

- $\hat{\sigma}$ = `r data_summary$sigma`

We construct a 95% confidence interval for $\hat{\beta_1}$. It is given by: 
```{r}
t_val = qt(p = 1 - (0.05)/2, df = data_summary$df[2], lower.tail = TRUE)
```

$$ `r data_summary$coefficients[2]` \pm `r t_val * data_summary$coefficients[4]`$$

Which is equal to: 

$$ `r data_summary$coefficients[2] - t_val * data_summary$coefficients[4]`,\quad `r data_summary$coefficients[2] + t_val * data_summary$coefficients[4]`$$

We also manually verify the result with: 
```{r}
confint(olympicLm)
```
(e) We now use the `anova` function to produce an ANOVA table for testing 

$$H_0: \beta_1 = 0\quad\quad vs\quad\quad H_1: \beta_1 \neq 0$$
```{r}
anova(olympicLm)
```
The t values given in the summary table is $7.925$ and the f value in the summary table is given by $62.813$. We see that: 
$$(7.925)^2 = 62.813$$Ignoring rounding errors. Hence, we have that the f statistics is the square of the t statistic. 

(f) We test the hypothesis of

$$H_0: \beta_1 = 0.25 \quad\quad vs\quad\quad H_1: \beta_1 > 0.25$$ 
```{r, include=FALSE}
beta_hat_1 = data_summary$coefficients[2]
se_beta_hat_1 = data_summary$coefficients[4]
observed_t_value = (beta_hat_1 - 0.25)/se_beta_hat_1
p_value = pt(q = observed_t_value, df = 18, lower.tail = FALSE)
```

  1. Under the Null hypothesis we have our test statistic to be
    
  $$T =  \frac{\hat{\beta_1} - \beta_1}{SE(\hat{\beta_1})} \thicksim t_{18}$$
    Now since we have that $\hat{\beta_1} = `r beta_hat_1`$ and $SE(\hat{\beta_1}) = `r se_beta_hat_1`$ we have that the observed statistic is:
  $$t_0 = `r observed_t_value`$$
  
  2. Hence our p value is given by: 
  $$\text{p value} = P(T > t_0) = `r p_value`$$
  
```{r, include=FALSE}
msg = ""
if (p_value < 0.05) {
  msg = "Since the p value is less than 0.05 we reject the null hypothesis"
} else {
  msg = "Since the p value is greater than or equal to 0.05 we fail to reject the null hypothesis"
}
```

`r msg`
  
  